\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{fullpage}
\usepackage[]{units}
\usepackage{xskak}
\usepackage{chessfss}
\usepackage{multicol}
\usepackage{natbib}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\usepackage[hyphenbreaks]{breakurl}
\usepackage{appendix}

\newcommand{\ICE}[0]{{\bf ICE}}

\begin{document}

\title{Proyecto IIA - ICE Chess Engine}

\author{Guido Martínez \\ LCC, FCEIA, UNR }

\maketitle

\begin{abstract}
En este documento se expone un motor de ajedrez
XBoard\cite{protocol}-compatible llamado \ICE{} desarrollado para la
materia ``Introducción a la Inteligencia Artificial'', realizado con el
objetivo de investigar las técnicas clásicas y actuales del ajedrez
por computadora. El motor se escribió desde cero en C, teniendo como
prioridad la fuerza del motor (por lo tanto: la eficiencia) y, en un
segundo lugar, la claridad y modularidad del código.
\\

El motor emplea una búsqueda Alpha-Beta con búsqueda de Quietud en los
nodos terminales. Se emplean, entre otras, las heurísticas Null-Move,
Late move reduction y tablas de transposición.
\end{abstract}

\begin{multicols}{2}

\section{Introducción}

El problema se plantea como un juego suma-cero \footnotemark de dos
jugadores de información perfecta. ``Información perfecta'' se refiere
a que ambos jugadores están completamente al tanto del estado del
juego, y no hay elementos ``escondidos''. Además, no tiene ningún
elemento de azar. Esto hace que el problema pueda ser resuelto con el
algoritmo Minimax\cite{norvig-russell}.
\\

\footnotetext{Brevemente, los juegos suma-cero son aquellos en los
cuales una ganancia de un jugador es una pérdida directa del otro, y no
existe la posibilidad de cooperación}

Sin embargo, el espacio de búsqueda es gigantesco: estimado alrededor
de $10^{40}$ tableros distintos, y $10^{120}$ juegos posibles. Para
realizar la búsqueda de un módo factible se limita la profundidad de
la misma, empleando una \emph{heurística de evaluación de tablero}
en los nodos terminales. Esto, naturalmente, causa que no se obtengan
soluciones certeras, si no aproximadas.
\\

La evaluación de tablero debe reflejar que tan buena es una posición,
y requiere de mucho conocimiento específico del dominio.
\\

Para optimizar el algoritmo Minimax se usa la poda Alpha-Beta y un
conjunto de heurísticas, tanto \emph{teóricamente correctas}(\emph
{sound}) como \emph{incorrectas}(\emph{unsound}). Una heurística se
llama teóricamente correcta si no afecta el resultado de la búsqueda,
excepto tal vez cuando hay un ``empate''.

\section{Representación de tablero}

A cada nodo de la búsqueda, el cual contiene toda la información del
juego al momento (posición de las piezas, cantidad de movidas, etc.) se
lo llama ``Tablero''.
\\

Se mantiene un sólo tablero en memoria en cada momento dado, haciendo
y deshaciendo movidas a medida que la búsqueda progresa (enfoque
Make-Unmake). Esto se ve facilitado por el hecho de que las búsquedas
son en profundidad.
\\

Se usa un array de 8x8 con las piezas. También se usan bitmaps de
64 bits (representando si una casilla está ocupada por una pieza
blanca o negra) para acelerar varios cálculos. En la estructura del
tablero, además de estar la información del juego en sí, se mantienen
incrementalmente:

\begin{itemize}
\setlength\itemsep{0em}
\item Puntaje de piezas de cada lado
\item Posiciones de los Reyes
\item Hash de 64 bits del nodo
\item Puntajes pieza-posición
\item Bitmaps de piezas
\item Rank de peones
\item Estado de Jaque
\end{itemize}

Mantener estos datos incrementalmente acelera mucho al motor, debido
a que muchos tienden a mantenerse contantes y/o ser fáciles de calcular
a partir de un valor previos.
\\

El hash del nodo fue específicamente elegido debido a que su cálculo
es perfectamente incremental con cada movida y da una distribución muy
regular (\emph{Zobrist hashing} \cite{wiki:zobrist}).

\section{Diseño general}

El motor efectúa una búsqueda Alpha-Beta sobre un grafo \emph{implícito}
del árbol del juego. Debido a que el algoritmo Alpha-Beta procede
por profundidad, es inútil mantener el árbol del juego en memoria, y
de hecho también sería muy costoso.
\\

Para realizar la búsqueda sobre un nodo primero se le generan las
movidas \emph{pseudo-sucesoras}. Cada una de estas movidas es evaluada
y puntuada para hacer un ordenamiento (dado que el algoritmo Alpha-Beta
funciona mejor cuando las mejores movidas son exploradas primero).
Una vez ordenadas por puntaje, la búsqueda continua iterando por los
sucesores ordenados.
\\

Este proceso es afectado por algunas heurísticas (Null-move y Late Move
Reduction). Estas diferencias se detallan más adelante.
\\

Por \emph{pseudo-sucesoras} nos referimos a que se consideran algunas
movidas que pueden no ser realmente válidas, como por ejemplo
alguna movida que deje al jugador en jaque. La razón de esto es que
para verificar que una movida es realmente válida debemos hacer
bastante trabajo, y por la naturaleza del Alpha-Beta es probable que
aunque generemos 30 sucesores, encontremos un corte mucho antes de
llegar al último, por lo cual ese trabajo fue inútil. Usar movidas
pseudo-sucesoras acelera mucho al programa, sin cambiar en lo absoluto
su funcionalidad (se visitan exactamente los mismos nodos en el mismo
orden).
\\

\section{Búsqueda}
Aquí se detalla cada componente de la búsqueda.

\subsection{Algoritmo Alpha-Beta}

El algoritmo Alpha-Beta es una mejora al algoritmo clásico Minimax, y
ante un mismo árbol de búsqueda siempre da lo mismos resultados, con
una complejidad temporal mucho menor en promedio.
\\

El Minimax más básico funciona explorando recursivamente el árbol
de movidas del juego. El caso base son los nodos terminales (juego
finalizado).Estos nodos terminales tienen como valor un número
representando el ``puntaje'' del jugador 1 (por convención). De está
manera el jugador 1 trata de maximizar ese resultado, y su oponente
trata de minimizarlo.
\\

Para un nodo no-terminal, se calcula el valor de los sucesores y
devuelve el valor máximo o mínimo, dependendiendo de si es el turno
del jugador maximizante o minimizante. Se puede guardar la movida
que causa el mejor puntaje y guardarla, haciendo que algoritmo
devuelva no sólo el puntaje esperado, si no también la movida
para conseguirlo.
\\

Para el Ajedrez, podemos tomar $1$ cuando ganan las blancas, $-1$ cuando
ganan las negras y $0$ para los empates.
\\

Debido a la imposibilidad de explorar el árbol entero, usamos una
condición de corte y aplicamos una \emph{heurística de evaluación de
tablero} en los cortes. Esto causa que el algoritmo no de resultados
completamente correctos, y pone a la \emph{evaluación de tablero} en
un lugar principal del motor.
\\

Está evaluación de tablero guiará la búsqueda casi en su totalidad,
por lo cual es necesario que realmente se corresponda con la situación
y dé puntajes adecuados según quién va en ventaja. También es
necesaria cierta estabilidad de esta función. Citando a
\href{http://chessprogramming.wikispaces.com/}
{chessprogramming.wikispaces.com}:
\\

\emph{``It is better to be wrong by 10 centipawns all the time than to
be completely correct 99.9\% of the time and wrong by 300 centipawns
0.1\% of the time.''}
\\

\subsubsection{Poda Alpha-Beta}

El algoritmo Minimax tiene una peculiaridad, si al analizar la primera
movida que podemos hacer generamos un jaque mate (el mejor resultado
posible), la búsqueda seguirá y calculará los valores esperados de
todos los nodos del árbol. Esto introduce una mejora significante: la
poda Alpha-Beta.
\\

El algoritmo Alpha-Beta extiende al Minimax llevando cuenta de una
``ventana'' de búsqueda. Dos valores llamados Alpha y Beta que
representan respectivamente los puntajes ``garantizados'' del jugador
maximizante y minimizante. Por garantizado se entiende a que el jugador
puede ``forzar'' un resultado de al menos ese puntaje. Ambos se inician
en el peor resultado posible ($-\infty$ y $+\infty$ respectivamente)
y se actualizan en la búsqueda. Si en algún vemos que una movida
del jugador maximizante resulta en un puntaje mayor a Beta, podemos
asegurar que esta rama que estamos explorando no tiene sentido, debido
a que jugador minimizante seguiría otra rama (la que le da el puntaje
garantizado) en vez de la actual.
\\

El mismo corte puede ocurrir en turnos del jugador minimizante. El
algoritmo Alpha-Beta siempre da el mismo resultado que Minimax (o sea,
es una mejora teóricamente correcta), pero su complejidad temporal
promedio disminuye de $O(b^d)$ a $O(b^{(3d/4)})$\footnotemark. Lo
que significa que podemos hacer una búsqueda de un 33\% más de
profundidad en el mismo tiempo. La complejidad en el peor caso se
mantiene ($O(b^d)$) y la del mejor caso es aún mejor: $O(\sqrt{b^d})$
(o sea, el doble de profundidad en el mismo tiempo).
\\

\footnotetext{$b$ es el factor de ramificación promedio y $d$ la
profundidad de la búsqueda}

El mejor caso se da cuando la mejor movida en cada nodo es la
primera analizada. Por esto mismo, se dedica mucho trabajo a ordenar
los sucesores. Para lograr esto se emplean muchas heurísticas de
ordenamiento de movidas.
\\

\subsubsection{Quiescence}

En las hojas de la búsqueda Alpha-Beta, no se aplica la evaluación
de tablero directamente, si no que se realiza otro tipo de búsqueda
conocida como Búsqueda de quietud (\emph{Quiescence search}). Esta
búsqueda es un Alpha-Beta similar al anterior, pero solo considera
como movimientos válidos a los movidas que producen una captura
o promoción. El objetivo es no aplicar la evaluación de tablero
ciegamente en tableros con piezas atacadas, y forzar a que se sigan
todas las líneas de capturas. Esto hace que se disminuya el Efecto
Horizonte\footnotemark y el motor juegue mucho mejor (en el mismo tiempo).
\\

\footnotetext{El efecto Horizonte ocurre cuando un motor toma malas
decisiones que se hubieran evitado por extender la búsqueda en pocas
movidas}

La búsqueda de quietud no está limitada por profundidad. En contraste,
solo termina por cortes Alpha-Beta, con la diferencia que al iniciar
la búsqueda usamos el valor actual del tablero como cota inferior de
$\alpha$ (similarmente a la Null move heuristic). Esto tiene algún
fundamento teórico, porque \emph{por lo general} siempre podemos
elegir una movida que no sea una captura y terminar con la secuencia de
capturas.
\\

\subsubsection{Alto nivel}

En rasgos generales, la búsqueda es como se describió anteriormente,
pero aumentando la profundidad iterativamente hasta llegar a un límite
de tiempo, o cuando la heurístima Smart-Stop decida efectuar la movida.
Cuando el tiempo se termina, se devuelve el resultado de la última
búsqueda que se completó íntegramente (no se aprovechan resultados
parciales).
\\

Se usa una técnica conocida como \emph{Aspiration Windows}, en donde se
usa el resultado de la búsqueda $i - 1$ para definir una ventana de la
búsqueda $i$. Por ejemplo, si la búsqueda a profundidad 5 dió como
resultado el puntaje 23, y nuestra ventana de aspiración es de 20, la
búsqueda 6 se llamará con Alpha y Beta iniciales iguales a 3 y 43.
\\

Hacer esto mejora mucho el rendimiento ya que al tener una ventana más
chica se visitan menos nodos. Pero, no siempre es el caso que la cota
es correcta, por lo que la búsqueda se rehace si el resultado no cae
dentro de los Alpha y Beta originales.

\subsection{Smart-Stop}

La heurística Smart-Stop es una forma de evitar etapas de la búsqueda
incompletas cuando ocurre un corte por tiempo. Estas etapas con
completamente desperdiciadas, y si se pudiera obviarlas el motor
tendría más tiempo en el reloj para las próximás movidas.
\\

Se basa en la observación de que el árbol de búsqueda crece cada vez
a medida que aumentamos la profundidad. Llamemos $t(i)$ al tiempo que
tarda la búsqueda hasta una profundidad $i$. Podemos asumir (para la
gran mayoría de los tableros) que $t(i+1) > t(i)$. Si $T$ es el tiempo
restante al terminar la búsqueda $i$-ésima y tenemos $T < t(i+1)$, se
puede concluir que la búsqueda terminará por tiempo y evitarla.
\\

Para evitar aún más de estos casos, en \ICE{} se asume que $t(i+1) >
2 \cdot t(i)$. Esto mostró mejores resultados, y casi ningún corte
espurio.
\\

Al saber del autor, esta heurística es original de \ICE{}.

\section{Heurísticas}

\subsection{Heurísticas de ordenamiento}

Debido a la naturaleza del Alpha-Beta, una heurística de ordenamiento
es siempre teóricamente correcta.

Todas estas heurísticas se aplican sobre la lista de movidas
pseudo-sucesoras y le dan un puntaje a cada una. Luego las movidas se
ordenan (de manera \emph{Lazy}) según la suma de todos los puntajes. En
cada heurística se detalla el puntaje empleado en \ICE{}.

\subsubsection{Killer move heuristic}
Una de las heurísticas de ordenamiento de movidas más simple y
rendidora es la Killer move heuristic. Consiste en guardar en una tabla
la movida que generó un corte, indexada por la profundidad en la cual
se hizo la movida. Al ejecutar de nuevo la búsqueda, si la movida
guardada aparece como sucesora se le suma un puntaje fijo (1000).
\\

\subsubsection{Tabla de transposición}
La tabla de transposición es la manera de eliminar nodos duplicados
en la búsqueda. Al usar Alpha-Beta no podemos simplemente guardar el
resultado que devolvimos, si no que también hay que tener en cuenta
el contexto en el cual lo generamos (la ventana), y saber si estamos
tratando con un resultado exacto, o una cota superior o inferior.
\\

Supongamos que el verdadero valor del tablero es $V$. Si la búsqueda
fue llamada con $\alpha$ y $\beta$ y devuelve $v$, tenemos 3
posibilidades:

\begin{itemize}
\item Si $v \le \alpha$ entonces $v \ge V$
\item Si $v \ge \beta$ entonces $v \le V$
\item Si $\alpha < v < \beta$ entonces $v = V$
\end{itemize}

Cuando guardamos el valor en la tabla, indicamos cual fue el caso y lo
tenemos en cuenta al volver a visitar el nodo.
\\

También, guardamos en la TT la movida que causó un corte y la
puntuamos con un bonus alto (10000). Por esto es también una
heurística de ordenamiento.

\subsubsection{Countermove heuristic}
Es una heurística similar a la Killer Move, pero en vez de registrar
los cortes indexados por la profundidad de la búsqueda, lo hace según
la movida realizada anteriormente a la actual, bajo la premisa de que
hay movidas que tienen una ``respuesta natural'' independientemente de
la profundidad y el tablero. Da resultados no muy buenos, pero es fácil
de implementar. El puntaje es 500.

\subsubsection{MVV-LVA}
MVV-LVA significa ``\emph{Most valuable victim, least valuable
attacker}'', es una heurística simple que puntúa las capturas. Una
captura es mejor que otra si captura a una pieza de mayor valor, o
realiza la captura con una pieza propia de menor valor. La fórmula
usada para puntuar es $10*v - a$ en donde $v$ es el puntaje de la pieza
víctima y $a$ el puntaje de la pieza atacante.
\\

Si bien MVV-LVA es da puntajes mucho menores, es de vital importancia
debido a que puntúa \emph{todas las capturas}. Funciona bastante
bien para ser algo tan simple de implementar. En especial para la
búsqueda de quietud, en donde sólo consideramos las capturas. Hace
una diferencia muy importante en ese caso debido a que no tenemos un
límite de profundidad como en la búsqueda principal y dependemos casi
exclusivamente de los cortes.

\subsection{Heurísticas de corte o reducción}

Las heurísticas de Null Move y Late Move Reductions no son
teóricamente correctas, pero dan muy buenos resultados al
implementarse. Es notable que al recortar nodos no necesariamente se
pierder fuerza del motor. De hecho, como \ICE{} hace profundización
iterativa, una buena estimación es que el motor siempre recorrerá
la misma cantidad de nodos en un tiempo dado, por lo que lo que hacen
las heurísticas es simplemente dirigir la búsqueda por los caminos
más interesante (al hacer un corte en una rama, exploraremos más por
todas las otras). Es vital tener en cuenta eso para pensar sobre las
heurísticas siguientes.

\subsubsection{Null move heuristic}
La heurística consiste en la idea intuitiva de que si podemos ceder el
turno, dándole 2 movidas a nuestro adversario, y seguimos teniendo un
tablero bueno, entonces nuestro tablero original era también bueno y
podemos cortar la búsqueda.
\\

En términos computacionales esto se implementa cediendo el turno,
realizando una búsqueda menos profunda del tablero (por ejemplo, de 3
plies menos) y comparando el resultado con $\beta$. Si el resultado es
mayor a $\beta$, devolvemos $\beta$ como resultado.
\\

Esto recorta mucho los nodos explorados para una cierta profundidad,
pero debido a la ilegalidad de la movida debemos tener cuidado de evitar
situaciones en donde mover nos perjudica (llamado Zugzwang). En \ICE{}
se evita aplicar NMH cuando estamos en Jaque o tenemos pocas piezas.

\subsubsection{Late Move Reductions}
La heurística LMR sigue la idea de que dado un buen ordenamiento de
movidas, es muy probable que las mejores movidas estén siempre al
principio de los sucesores, con lo cual es casi seguro que las movidas
del final de la lista fallen bajo (resulten $< \alpha$).
\\

A las movidas del final de la lista (que cumplen un conjunto de
condiciones selecto para no reducir caminos importantes) se les reduce
su profundidad máxima en 1. Si resulta que no fallan bajo (o sea,
devuelven un valor mayor o igual a $\alpha$), la búsqueda se rehace con
la profundidad normal.

\section{Evaluación de Tablero}
Se sigue la convención de que los valores positivos favorecen al
jugador blanco y los negativos al negro. La evaluación de tablero se
hace sumando los siguientes puntajes.

\subsection{Valor de piezas}
Simplemente se suman los valores de cada pieza que tiene cada jugador. Las piezas blancas tienen valor positivo y las negras negativo. Los valores son:

\begin{center}
 \begin{tabular}{ccc}
  \WhitePawnOnWhite = 100 & \WhiteKnightOnWhite = 320 & \WhiteBishopOnWhite = 320 \\
  \WhiteRookOnWhite = 500 & \WhiteQueenOnWhite = 900  & \\
 \end{tabular}
\end{center}

Los reyes no tienen puntaje, debido a que siempre están y no influiría
en nada.

\subsection{Pieza-posición}
Una mejora simple a lo anterior es darle puntajes a las piezas según la
posición. Para esto se definen 6 tablas de 64 casillas con puntajes.
De esta manera se puede darle mejor puntajes a los caballos cerca del
centro, o a los peones más avanzados. Estos puntajes suelen ser menores
a los anteriores, debido a que perder piezas es algo mucho más severo.
\\

Para el caso del rey, queremos que ocupe posiciones completamente
distintas en la apertura y en el juego final, por lo que usamos dos
tablas, e interpolamos según la etapa del juego.
\\

Las tablas pieza-posición fueron tomadas de \cite{piece-square-table} y
ligeramente modificadas.

\subsection{Estado de Jaque}
Se aplica una penalización por no haber hecho enroque, y una más severa
si ya no es posible. Esto incentiva al motor a realizar el enroque.

\subsection{Estado de filas}
Se evalua cada fila del tablero según los peones de cada jugador. Si
una fila no tiene peones se la llama \emph{abierta}. Si tiene peones de
un sólo jugador se la llama \emph{semi-abierta}.
\\

Una fila abierta es bastante significativa. Tener una fila abierta cerca
de nuestro rey es malo, y se aplica un penalización. Tener una torre en
una fila abierta es muy bueno y merece un bonus.

\subsection{Estado de jaque}
Si bien tratamos de no aplicar la evaluación de tablero en tableros
en jaque (preferimos extender la búsqueda) ciertas situaciones causan
que no se pueda seguir extendiendo. Si se da una de estas situaciones
restamos 100 puntos al lado en jaque, para incentivar a que se exploren
otras alternativas.

\subsection{Bonus por par de alfiles}
Simplemente si uno de los lados tiene ambos alfiles, se le da un bonus.

\subsection{King safety}
Para cada lado se evalua que tan bien está protegido el rey. Esto se
hace considerando el estado de las filas cercanas. Tener filas abiertas
es penalizado, y también se prefiere tener a los peones propios cerca y
a los del oponente lejos.
\\

El valor de King-safety se escala según las piezas del oponente. La
premisa es que un rey sólo puede estar descubierto si el oponente tiene
material para poder atacarlo.
\\

Esto está fuertemente inspirado en el motor TSCP\cite{tscp} de Tom
Kerrigan.

\subsection{Evaluación lazy}

Uno de los puntos más costosos del motor es la evaluación de cada
pieza. Para tratar de evitar esto, se divide a la evaluación en
etapas\cite{lazy-eval}, cada una con una cota. Cuando se debe evaluar un
nodo, se procede por etapas, teniendo en cuenta las cotas de las etapas
siguientes.
\\

Llamemos $ev(i)$ a la evaluación del tablero hasta la etapa $i$-ésima
y $C$ a la suma de las cotas de todas las etapas siguientes. Si ocurre
que $ev(i) - C > \beta$, entonces la verdadera evaluación también
será mayor a $\beta$, con lo cual se puede concluir que ocurrirá un
corte y dejar de evaluar el nodo (devolver $\beta$).

\section{Extensiones/Reducciones}

\subsection{Extension por Jaque o promoción}
Simplemente si el tablero actual está en Jaque, o la última movida fue
una promoción de un peón, se agrega 1 a la profundidad máxima de la
rama. Esto incentiva a resolver los Jaques y promociones y no aplicar la
evaluación en un tablero muy inestable.

\subsection{Extensión por movida forzada}
Si el tablero actual tiene una sola movida posible, se agrega 1 a la
profundidad máxima, debido a que este nivel fue ``desperdiciado'' de
alguna manera.
\\

Esto sólo puede saberse cuando terminamos la búsqueda en el nodo
(debido a que no sabemos cuales de las pseudo-sucesoras son válidas
hasta ese momento), por lo cual la búsqueda es reiniciada con mayor
profundidad. La gravedad de esto es disminuída por la tabla de
transposición.

\section{Resultados}
Durante el desarrollo se usó de oponente a Fairymax\cite{fairymax},
un motor de ajedrez basado de $\mu$-Max (Micro-Max) que juega a un
nivel intermedio ($\sim$2000 ELO\cite{wiki:elo}). En su versión 0.7,
\ICE{} parece ser claramente superior. Se corrieron 400 partidas en
formato 40/4 (40 movidas en 4 minutos) y el resultado fue 225-91-84
(victorias-empates-derrotas) a favor de \ICE{}.

Para la modalidad 40/1 (partidas más rápidas) el resultado fue mas
marcado: 249-79-72.

El registro de partidas se puede encontrar aquí:
\url{http://labdcc.fceia.unr.edu.ar/~gmartinez/ice/fairy\_40\_4.pgn.gz}
y
\url{http://labdcc.fceia.unr.edu.ar/~gmartinez/ice/fairy\_40\_1.pgn.gz}

\section{Reflexiones y trabajo futuro}
Sin duda algo a mejorar de \ICE{} es la evaluación de tablero. Escribir
una buena función de evaluación de tablero requiere muchísimo
conocimiento del dominio, y por lo general es llevado a cabo por
expertos en el juego junto a programadores. La evaluación actual es muy
básica.
\\

Se podría paralelizar la búsqueda\cite{parallel-ab}, aunque esto
es algo no trivial debido a la naturaleza secuencial del Alpha-Beta.
Al paralelizar seguramente exploraríamos más nodos que de forma
secuencial (debido a que no tendremos la ventana exacta), Sin embargo,
se observan mejoras notables en otros motores como crafty \cite{crafty}
\cite{crafty-threads}.
\\

Otras mejoras pueden ser hacer que el límite de tiempo sea algo más
inteligente: podría tener en cuenta cuanto tiempo lleva usado cada
jugador, y el límite del partido, si es que existe, para evaluar
mejor cuanto tiempo dedicar a una movida. Independientemente, se puede
hacer que \ICE{} trabaje durante el turno del oponente (conocido como
\emph{Pondering}\cite{pondering} \cite{wiki:pondering}).
\\

En algunos casos, con pocas movidas posibles, es bastante claro para un
humano cual es la movida a elegir. Por ejemplo, si tenemos la opción
entre avanzar un peón y mover la reina, estando la reina amenazada,
es casi seguro que debemos mover la reina. Si bien el Alpha-Beta
funcionará rápido al detectar cortes ``evidentes'', podríamos tomar
menos tiempo para esta movida. Evaluar esta idea e implementarla puede
ser un trabajo futuro.
\\

Por alguna razón, muchas partidas de \ICE{} contra Fairymax terminan
en empates, incluso antes de llegar al juego medio (la partida 1
del apéndice es un ejemplo). No se conoce bien la causa de esto.
Investigarlo podría dar frutos.
\\

Otras mejoras incluyen implementar nuevas heurísticas como Futility
Pruning o cambiar el método de búsqueda a PVS o MTD(f).
\\

Algo pendiente es inscribir a \ICE{} en un torneo de motores y ver los
resultados. De esta manera tendremos una buena estimación del puntaje
ELO del motor, algo que aún no se calculó.

\bibliographystyle{plain}
\bibliography{bib.bib}

\end{multicols}

\newpage
\appendix
\section{Algunos finales de \ICE{} vs Fairymax}

\newcommand{\tie}[0]{\nicefrac{1}{2}-\nicefrac{1}{2}}
\newcommand{\game}[2]{
	\newchessgame
	\parbox{0.5\textwidth}{
	\begin{center}
	 #2 \\
	 \hidemoves{#1}
	 \chessboard[arrow=to,
		       smallboard,
		       lastmoveid,
		       showmover=false,
		       pgfstyle=straightmove,color=red,
		       markmove=\xskakget{movefrom}-\xskakget{moveto},
	 ]
	\end{center}
	}
}

\begin{multicols}{2}

\game{1.e4 e5 2.Nf3 Nc6 3.Nc3 Nf6 4.g3 Bc5 5.Bg2 d6 6.d3 a6 7.O-O O-O
8.Re1 Ng4 9.Rf1 Nf6 10.Re1 Ng4 11.Rf1 Nf6}
{1. \ICE{}-Fairymax \tie \\
Empate por repetición}

\game{1. d4 Nf6 2. c4 e6 3. Nc3 Bb4 4. e3 b6 5. Ne2 Ne4 6. Bd2 Nxd2 7.
Qxd2 O-O 8. a3 Be7 9. Nf4 Nc6 10. O-O-O g5 11. Nh3 d5 12. Qe2 dxc4 13.
Qxc4 Bb7 14. f4 gxf4 15. Nxf4 Bd6 16. Nb5 Bxf4 17. exf4 Qf6 18. d5 Na5
19. Qb4 exd5 20. Rd3 c5 21. Rg3+ Kh8 22. Qd2 Rfc8 23. Qf2 d4 24. a4 a6
25. Na3 Bc6 26. Nc4 Nxc4 27. Bxc4 Bxa4 28. Rg5 Re8 29. Bd3 h6 30. Rf5
Qg6 31. Qh4 Re6 32. Re1 Rxe1+ 33. Qxe1 Qxg2 34. Rh5 Kg7 35. Qe5+ Kg8 36.
Qe2 Qg1+ 37. Qf1 Qxf1+ 38. Bxf1 Kg7 39. Rh3 c4 40. Bxc4 Rc8 41. Rg3+ Kf6
42. b3 b5 43. bxa4 bxc4 44. Rh3 Kg6 45. Kc2 Rc6 46. Rg3+ Kf5 47. Rg7 Rf6
48. Rg2 Kxf4 49. h3 Ke3 50. h4 Rf2+ 51. Rxf2 Kxf2 52. Kb2 Ke1 53. Ka3 d3
54. Kb4 d2 55. Kxc4 d1=Q 56. Kc5 Qxa4 57. h5 Qd7 58. Kc4 Qc6+ 59. Kd3
Kf2 60. Kd4 Kg2 61. Kd3 Qc5 62. Ke4 Qc4+ 63. Ke5 Qc5+ 64. Ke4 Qd6 65.
Kf5 Kf1 66. Kg4 Qe5 67. Kf3 Kg1 68. Kg4 Kg2 69. Kh4 Qg5\# }
{2. Fairymax-\ICE{} 0-1 \\
Jaque mate}

\game{1. c4 c6 2. Nf3 d5 3. d4 Nf6 4. e3 Bf5 5. Nc3 e6 6. Nh4 Be4 7. Qb3
Qc7 8. Nxe4 dxe4 9. f4 Be7 10. Bd2 Nbd7 11. O-O-O Nh5 12. g3 Bxh4 13.
gxh4 Nhf6 14. Be2 O-O 15. Qc3 c5 16. Rdg1 cxd4 17. exd4 Kh8 18. Rg5 Rg8
19. Be3 h6 20. Ra5 Rgd8 21. h5 Kg8 22. Rb5 Ne8 23. Rg1 Ndf6 24. Rc5 Qd7
25. f5 exf5 26. Bxh6 Kh7 27. Bf4 Qxd4 28. Qxd4 Rxd4 29. Rxf5 Rd7 30. a4
Rc8 31. b3 Rc6 32. Rfg5 Rd5 33. h4 Rd8 34. Be3 a6 35. c5 Rdc8 36. Bc4
R6c7 37. Rf1 Re7 38. Rf4 Rc6 39. Rf2 Rcc7 40. Rff5 Red7 41. Rg3 Rc6 42.
Rfg5 Rc8 43. b4 Rcd8 44. b5 axb5 45. axb5 Rc8 46. b6 Rcd8 47. Rf5 Ra8
48. Kc2 Rc8 49. Rg1 Re7 50. Rg2 Nd7 51. Rxf7 Rxf7 52. Bxf7 Nef6 53. Be6
Rc6 54. Bf5+ Kh8 55. h6 gxh6 56. Bxd7 Nxd7 57. Bd4+ Nf6 58. Rg6 Kh7 59.
Rxf6 Rc8 60. c6 bxc6 61. Be5 Re8 62. b7 c5 63. Bd6 Kg7 64. Rf8 Rxf8 65.
Bxf8+ Kxf8 66. b8=Q+ Kf7 67. Qb6 Ke7 68. Qxh6 Kd7 69. h5 Kc7 70. Qe3
Kc6 71. h6 Kd5 72. h7 Ke5 73. h8=Q+ Ke6 74. Qxe4+ Kd7 75. Qhh7+ Kd6 76.
Qhe7\# }
{3. Fairymax-\ICE{} 1-0 \\
Jaque mate}

\game{1. e4 c5 2. Nf3 d6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 Nc6 6. f3 e6 7.
Be3 Be7 8. Qd2 O-O 9. O-O-O d5 10. exd5 Nxd5 11. Nxd5 Qxd5 12. c4 Qd6
13. Nxc6 Qxc6 14. Be2 e5 15. Qc3 Bf6 16. Qc2 Be6 17. Bd3 h6 18. Bh7+ Kh8
19. Be4 Qa6 20. a4 Bxc4 21. Bc5 Rfc8 22. b4 b6 23. Bxa8 bxc5 24. b5 Bxb5
25. axb5 Bg5+ 26. Kb2 Qxb5+ 27. Qb3 Qe2+ 28. Qc2 Rb8+ 29. Kc3 Qxc2+ 30.
Kxc2 Rxa8 31. Rd5 Rc8 32. Rxe5 Rc7 33. Re8+ Kh7 34. Ra1 Bf6 35. Ra2 c4
36. Ra8 Bd4 37. Ra4 Kg6 38. h3 Bf2 39. Rd8 Kf5 40. g4+ Kf4 41. Rd3 Kg3
42. Rc3 Bb6 43. f4+ Kxf4 44. Raxc4+ Rxc4 45. Rxc4+ Kg5 46. Rc3 h5 47.
gxh5 Kxh5 48. Rf3 Kg6 49. Kc3 f5 50. Kc4 Kg5 51. Rg3+ Kf6 52. Kd5 f4 53.
Rg4 Be3 54. Ke4 a5 55. h4 a4 56. h5 Kf7 57. Rg6 a3 58. Rc6 Bd2 59. Rc2
Bb4 60. Kxf4 Ke6 61. Kg5 Kd5 62. Kg6 Bc5 63. Ra2 Kc4 64. Rc2+ Kd5 65.
Ra2 Kc4 66. Rc2+ Kb4 67. Kf5 Bd4 68. Ke4 Kb3 69. Kd3 Be5 70. Rc6 a2 71.
Rb6+ Ka3 72. Ra6+ Kb2 73. h6 gxh6 74. Rb6+ Kc1 75. Rc6+ Kb1 76. Rxh6 Bb2
77. Ra6 a1=Q 78. Rxa1+ Kxa1}
{4. Fairymax-\ICE{} \tie \\
Material insuficiente}

\game{1. c4 e5 2. Nc3 Nf6 3. g3 Bb4 4. Nf3 Nc6 5. Nd5 Bc5 6. Bg2 d6 7.
O-O O-O 8. d3 Nxd5 9. cxd5 Nd4 10. Nxd4 Bxd4 11. e3 Bb6 12. e4 c6 13.
dxc6 bxc6 14. Be3 Be6 15. d4 Qf6 16. d5 cxd5 17. Bxb6 axb6 18. exd5 Bf5
19. Qb3 h6 20. Rfc1 Rfd8 21. Rc4 Rdb8 22. Rc6 b5 23. Qb4 Bd7 24. Qxd6
Bxc6 25. Qxf6 gxf6 26. dxc6 Ra7 27. Rd1 Kg7 28. Bd5 Rd8 29. Kf1 b4 30.
Ke1 f5 31. Bb3 Rxd1+ 32. Kxd1 Kf6 33. Kc2 Ke7 34. Kd3 Kd6 35. Kc4 Kxc6
36. Kxb4 f6 37. a4 h5 38. Bc2 e4 39. Kc3 h4 40. b4 h3 41. b5+ Kc5 42.
Kd2 Kb4 43. Ke2 Kc3 44. Bd1 Rd7 45. Ke1 Kb4 46. Ke2 Rd4 47. Ke1 Kc5 48.
Bc2 Rb4 49. Kd2 Kd4 50. Ke1 Rb2 51. Kd2 Kc4 52. b6 Rxb6 53. Ke3 Rd6 54.
a5 Kc3 55. Ba4 Rd3+ 56. Ke2 Kb4 57. Be8 Ra3 58. Bf7 Rxa5 59. Be6 Re5 60.
Ba2 Rc5 61. Be6 Rc2+ 62. Ke3 Rc3+ 63. Ke2 Rc5 64. Ke3 Re5 65. Bc8 Ra5
66. Kd4 Rc5 67. Bd7 Rc4+ 68. Ke3 Rc3+ 69. Ke2 Rf3 70. Be8 Kc5 71. Bh5
Ra3 72. Bg6 Ra2+ 73. Ke3 Ra1 74. Bxf5 Re1+ 75. Kd2 Rf1 76. Ke3 Kd6 77.
Ke2 Rb1 78. Bxe4 Rb2+ 79. Ke3 Ke5 80. Bd3 f5 81. Bf1 Rb3+ 82. Ke2 f4 83.
Bxh3 f3+ 84. Kd2 Ke4 85. Kc2 Ra3 86. Kb2 Rd3 87. Kc1 Rc3+ 88. Kb2 Rc5
89. Bf1 Ke5 90. h3 Kd4 91. h4 Ra5 92. Kb3 Ra1 93. Bh3 Kd3 94. Bc8 Ke2
95. g4 Kxf2 96. Kb2 Rh1 97. Kc2 Kg3 98. h5 f2 99. Ba6 Kxg4 100. Kd2 Kf4
101. Kc3 Ke3 102. h6 Rxh6 103. Bf1 Rh1 104. Bg2 Re1 105. Kb4 Kf4 106.
Kc3 Rg1 107. Kd2 Rxg2 108. Ke2 Kg3 109. Kf1 Rg1+ 110. Ke2 f1=Q+ 111. Ke3
Qc4 112. Kd2 Rg2+ 113. Ke1 Qc1\#}
{5. \ICE{}-Fairymax 0-1 \\
Jaque mate}

\game{1. e4 c5 2. Nf3 Nc6 3. d4 cxd4 4. Nxd4 Nf6 5. Nc3 d6 6. Bg5 e6 7.
Qd2 Be7 8. O-O-O O-O 9. f4 h6 10. Bh4 e5 11. Nf5 Bxf5 12. exf5 Qa5 13.
a3 Rfd8 14. Be2 Nd7 15. Bxe7 Nxe7 16. Bf3 Nc5 17. g4 h5 18. f6 Ng6 19.
gxh5 Nxf4 20. Rhg1 g6 21. Qe1 Kf8 22. h6 Kg8 23. Qh4 Kh7 24. Ne2 Nxe2+
25. Bxe2 d5 26. Rgf1 Qb6 27. Rf3 Rac8 28. c3 d4 29. c4 e4 30. Rf2 Na4
31. Bd3 exd3 32. Rxd3 Rxc4+ 33. Kb1 Nc3+ 34. Rxc3 Rxc3 35. a4 d3 36. Rd2
Rc2 37. Rxc2 dxc2+ 38. Kxc2 Qc6+ 39. Kb1 Rd1+ 40. Ka2 Qd5+ 41. Qc4 Qxc4+
42. b3 Qc3 43. b4 Ra1\#}
{6. Fairymax-\ICE{} 0-1 \\
Jaque mate}

\game{1. e4 c5 2. f4 e6 3. Nc3 d5 4. Nf3 dxe4 5. Nxe4 Nc6 6. Bb5 Nf6 7.
Bxc6+ bxc6 8. d3 Nxe4 9. dxe4 Qxd1+ 10. Kxd1 Be7 11. Kd2 O-O 12. Kc3 f5
13. e5 a5 14. Nd2 Ba6 15. Nc4 Bxc4 16. Kxc4 Rab8 17. Rd1 Rb4+ 18. Kc3
Re4 19. Rd7 Rf7 20. g3 Re2 21. Rc7 c4 22. Rxc6 Bb4+ 23. Kxc4 Rxc2+ 24.
Kb5 Rb7+ 25. Ka6 Rxc6+ 26. Kxb7 Rc2 27. h3 h5 28. Ka6 Be1 29. a4 Bxg3
30. Kxa5 g5 31. fxg5 Bxe5 32. Rb1 f4 33. b4 f3 34. Be3 f2 35. Rf1 Bg3
36. b5 Re2 37. Bc5 e5 38. Kb6 Re1 39. Bxf2 Rxf1 40. Bxg3 e4 41. Kc6 Rc1+
42. Kd5 e3 43. b6 Rb1 44. Kc6 Rc1+ 45. Kb5 h4 46. Bxh4 Rf1 47. b7 Kg7
48. a5 e2 49. Kc5 Rc1+ 50. Kd5 Rd1+ 51. Kc4 Rc1+ 52. Kd3 Rd1+ 53. Kxe2
Rb1 54. a6 Rb2+ 55. Kd1 Rb1+ 56. Kc2 Rb6 57. Bg3 Rxa6 58. b8=Q Rc6+ 59.
Kd3 Rg6 60. Qe5+ Kg8 61. Qe8+ Kh7 62. Qf7+ Rg7 63. g6+ Kh6 64. Bf4+ Kh5
65. Qf5+ Kh4 66. Qg4\#}
{7. \ICE{}-Fairymax 1-0 \\
Jaque mate}

\game{1. d4 Nf6 2. c4 e6 3. Nc3 Bb4 4. Qc2 d5 5. cxd5 Qxd5 6. e3 c5 7.
Bd2 Bxc3 8. Bxc3 cxd4 9. Bxd4 Nc6 10. Bc3 O-O 11. Nf3 Rd8 12. Be2 Qe4
13. Qb3 h5 14. Bxf6 gxf6 15. O-O Rb8 16. Rad1 Bd7 17. Rd2 e5 18. Rfd1
Be6 19. Qb5 Re8 20. a3 Ne7 21. Qc5 Qc6 22. Qb4 Qb6 23. Qxb6 axb6 24. Rd6
Nc8 25. R6d3 Na7 26. Nd2 h4 27. Ne4 Kg7 28. Nd6 Re7 29. Rc3 Rd7 30. e4
Nc6 31. Bb5 Nd4 32. Bxd7 Ne2+ 33. Kf1 Nxc3 34. Rd3 Bxd7 35. Rxc3 Be6 36.
Ke2 Rg8 37. Rc7 h3 38. gxh3 Rh8 39. Rxb7 Rxh3 40. Rxb6 Rxh2 41. b4 Bg4+
42. Kf1 Kg6 43. Rb8 Bh3+ 44. Ke1 Rh1+ 45. Kd2 Ra1 46. Rg8+ Kh5 47. Ra8
Be6 48. b5 Rb1 49. Ra6 Rb2+ 50. Ke1 Rb1+ 51. Ke2 Rb2+ 52. Kf3 Bg4+ 53.
Kg2 Kg6 54. Kg3 Be2 55. a4 Rb3+ 56. Kh2 Rf3 57. Kg1 Rh3 58. Nf5 Ra3 59.
Kh2 Bd3 60. Nd6 Ra2 61. Kg2 Ra1 62. Ra8 Rb1 63. f3 Rb2+ 64. Kg3 Be2 65.
Rg8+ Kh7 66. Rf8 Rb3 67. Kf2 Bxf3 68. Rxf7+ Kg6 69. Rf8 Bh5 70. a5 Rf3+
71. Ke1 Re3+ 72. Kd2 Re2+ 73. Kd3 Re1 74. b6 Rb1 75. b7 Rb3+ 76. Kc4
Rxb7 77. Nxb7 Bd1 78. Nc5 Be2+ 79. Kd5 Kg7 80. Rxf6 Kxf6 81. a6 Bxa6 82.
Nxa6 Ke7 83. Kxe5 Kd7 84. Kd5 Kd8 85. e5 Ke8 86. e6 Kd8 87. Kd6 Ke8 88.
Nc7+ Kf8 89. e7+ Kg8 90. Ke5 Kh7 91. e8=Q Kh6 92. Kf6 Kh7 93. Qd8 Kh6
94. Qh8\#}
{8. \ICE{}-Fairymax 1-0 \\
Jaque mate}

\game{1. d4 Nf6 2. c4 e6 3. Nf3 b6 4. g3 Ba6 5. Qb3 Nc6 6. Nbd2 d5 7.
Bg2 Qd7 8. Ne5 Nxe5 9. dxe5 dxc4 10. Nxc4 O-O-O 11. O-O Qd4 12. exf6
Bxc4 13. Qf3 Rd5 14. Be3 Qxb2 15. Rfb1 Qxe2 16. Qxe2 Bxe2 17. Bxd5 exd5
18. Re1 Bc4 19. Bd4 gxf6 20. Bxf6 Rg8 21. Re8+ Kb7 22. Be5 Bb5 23. Rd8
Bc6 24. Bc3 a5 25. Rb1 Ka6 26. Bd2 Rh8 27. Rc1 Kb7 28. Bc3 Rg8 29. Bxa5
bxa5 30. Rb1+ Ka7 31. Rc8 Ka6 32. Rbb8 d4 33. Rxf8 Rxf8 34. Rxf8 Bd5
35. Rd8 c6 36. f4 Kb5 37. Kf2 Kb4 38. Ra8 Bxa2 39. f5 Bd5 40. f6 a4 41.
Rb8+ Kc3 42. Rb1 a3 43. Rc1+ Kb2 44. Re1 a2 45. Re2+ Kb3 46. Re1 Kc2 47.
Re2+ Kc3 48. Re1 d3 49. Rc1+ Kd2 50. Rf1 Kc2 51. Ke3 d2 52. Rf2 a1=Q 53.
Rxd2+ Kc3 54. Rd3+ Kc4 55. Ke2 Qb2+ 56. Ke3 Qe5+ 57. Kd2 Qg5+ 58. Ke2
Qh5+ 59. g4 Qxg4+ 60. Kd2 Qg2+ 61. Ke3 Qf3+ 62. Kd2 Qf2+ 63. Kc1 Kxd3
64. Kb1 Qc2+ 65. Ka1 Qc1\#}
{9. Fairymax-\ICE{} 0-1 \\
Jaque mate}

\game{1. c4 Nf6 2. Nc3 d5 3. cxd5 Nxd5 4. g3 g6 5. Bg2 Nb6 6. d3 Bg7 7.
Be3 Nc6 8. Nf3 Bxc3+ 9. bxc3 e5 10. Bh6 Qf6 11. O-O Qe7 12. a4 Nd7 13.
h4 Nf6 14. Qb3 Ng4 15. Bc1 Qe6 16. Qa3 h6 17. Rb1 f5 18. Bd2 e4 19. dxe4
fxe4 20. Nd4 Nxd4 21. cxd4 Rh7 22. f3 e3 23. Bc1 Nf6 24. Bxe3 Qe7 25.
Qxe7+ Rxe7 26. Bxh6 Rxe2 27. Bg5 Kf7 28. Rfc1 c6 29. Bf1 Re7 30. Bc4+
Kg7 31. g4 Rd7 32. Be6 Re7 33. d5 Bxe6 34. dxe6 Rae8 35. f4 Rc7 36. f5
Nxg4 37. Rd1 Nf6 38. Bf4 Rce7 39. Bd6 gxf5 40. Bxe7 Rxe7 41. Rd2 Nd5 42.
h5 Kf6 43. h6 Rh7 44. Re1 Rxh6 45. Rxd5 cxd5 46. e7 Rh8 47. e8=Q Rxe8
48. Rxe8 a6 49. a5 f4 50. Kf2 Kf5 51. Kf3 d4 52. Re7 d3 53. Rxb7 Ke5 54.
Rd7 Kf5 55. Rxd3 Ke5 56. Rd7 Kf6 57. Kxf4 Kg6 58. Ke5 Kg5 59. Rg7+ Kh4
60. Kf5 Kh3 61. Kf4 Kh2 62. Kf3 Kh1 63. Kf2 Kh2 64. Rh7\#}
{10. Fairymax-\ICE{} 1-0 \\
Jaque mate}

\end{multicols}

\end{document}
