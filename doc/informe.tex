\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{fullpage}
\usepackage{chessfss}
\usepackage{hyperref}

\renewcommand{\refname}{\section{Referencias}}

\begin{document}

\title{Proyecto IIA - ICE Chess Engine}

\author{Guido Martínez \\ LCC, FCEIA, UNR }

\maketitle

\section{Objetivo}

Crear una inteligencia artificial para jugar al ajedrez (un \emph {Motor
de Ajedrez}, usando métodos tradicionales. Priorizar el entendimiento
y claridad del código ante la performance, siempre que esto no haga a
nuestro motor demasiado lento como para competir con otros.

\section{Overview}

Como es usual, el algoritmo de búsqueda elegido es Alpha-Beta con una
búsqueda de quietud (\emph{Quiescence Search}) en los nodos terminales
de la búsqueda.
También se incluyen límites de tiempo para que una movida no tarde una
cantidad exagerada de tiempo, y se implementa el protocol \emph{xboard}
\cite{protocol} casi en su totalidad.
\\

Lo que mayormente define al motor son la representación del tablero,
las heurísticas de ordenamiento de movidas, las reducciones y
extensiones de búsqueda, y la evaluación de tablero.
\\

Para acelerar al motor, normalmente se usan una gran cantidad
de heurísticas. Algunas de estas son teóricamente correctas
(\emph{theoretically sound}) y otras no. Una heurística se llama
teóricamente correcta si no afecta el resultado de la búsqueda,
excepto tal vez por tomar otra variacion principal en el caso de que
haya mas de una con el mismo puntaje. Si pensamos a las funciones $S$ y
$S'$ ($S'$ emplea alguna heurística $H$) como búsquedas que devuelven
el \emph{conjunto} de variaciones principales de mayor puntaje, entonces
$H$ es teorícamente correcta si $S(g, d) = S'(g, d)$ para todo tablero
$g$ y profundidad $d$.

Pasamos a detallar detalles de nuestro motor
\\

\subsection{Representación de tablero}
Se usa un array de 8x8 con las piezas. También se usan máscaras
de 64 bits para acelerar algunos cálculos. En la estructura del
tablero, además de estar la información del juego en sí, se mantienen
incrementalmente (se ajustan/recalculan luego de cada movida):

\begin{itemize}
\item Puntaje de piezas de cada lado
\item Un hash del tablero para comparar rápidamente por igualdad
\item Los puntajes pieza-posición
\item Las máscaras de piezas
\item Rank de peones
\item Estado de Jaque
\item Posiciones de los Reyes
\end{itemize}

Se mantienen estos datos incrementalmente para no tener que recorrer
todo el tablero al momento de la evaluación para calcularlos. El hash
fue específicamente elegido debido a que su cálculo es incremental
con cada movida y da muy buenos resultados (\emph{Zobrist hashing}
\cite{zobrist}).

\subsection{Heurísticas de ordenamiento de movidas}

Las heurísticas usadas son (en orden del puntaje que aportan al
ordenamiento):
\begin{itemize}
\item Tablas de transposición
\item Killer Move Heuristic
\item Countermove Heuristic
\item MVV-LVA
\end{itemize}

\subsection{Reducciones}

\begin{itemize}
\item Null-move heuristic (para nodos \emph{fail-high})
\item Late move reduction (para nodos \emph{fail-low})
\item Corte de max score (trivial)
\end{itemize}

\subsection{Extensiones}
\begin{itemize}
\item Extensión por jaque
\item Extension por promoción
\end{itemize}

\subsection{Evaluación del tablero}
Para la evaluación del tablero se tienen en cuenta:
\begin{itemize}
\item Puntaje de piezas
\item Puntaje pieza-posición
\item Estado de jaque
\item Estado de filas
\item Estado de enroque
\item Bonus por par de alfiles
\item King-safety
\end{itemize}

Las tablas pieza-posición fueron tomadas de \cite{piece-square-table} y ligeramente modificadas.\\

\section{Diseño general}

Habiendo tantos motores de Ajedrez hechos, hay mucho material para
investigar. La mayoría de los motores optan por tener un sólo tablero
del juego en memoria (representado de diversas formas), y una \emph
{Pila de Historia} (\emph {History Stack}) con información para
deshacer las movidas hechas (Make-Unmake). Yo en un principio opté
opté por copiar el tablero original, realizar la movida sobre la copia
y luego descartar la copia al terminar de usarla (Copy-Make), pero luego
porté el motor al paradigma Make-Unmake.
\\

El motor realiza una búsqueda sobre un grafo \emph{implícito},
en donde el nodo actual es siempre el tablero en cuestión (el
único en memoria). A este tablero se le generan las movidas
\emph{pseudo-sucesoras}. Cada una de estas movidas es evaluada y
puntuada para hacer un ordenamiento (dado que el algoritmo Alpha-Beta
funciona mejor cuando las mejores movidas son evaludas primero). Una vez
ordenadas por puntaje, la búsqueda prosige hasta alguna profundidad (o
hasta que alguna heurística produzca un corte).
\\

Por pseudo-sucesoras nos referimos a que se consideran algunas movidas
que pueden no ser realmente válidas, como por ejemplo alguna movida que
deje al jugador en jaque. La razón de esto es que para verificar que
una movida es realmente válida debemos hacer bastante trabajo, y por la
naturaleza del Alpha-Beta es probable que aunque generemos 30 sucesores,
encontremos un corte mucho antes de llegar al último, por lo cual ese
trabajo nunca se haría. Usar movidas pseudo-sucesoras acelera mucho
al programa, sin cambiar en lo absoluto su funcionalidad (se visitan
exactamente los mismos nodos en el mismo orden)
\\

\section{Búsqueda}
Detallamos las técnicas usadas que son relevantes a la materia.

\subsection{Algoritmo Alpha-Beta}

El algoritmo Alpha-Beta es una mejora al algoritmo clásico Minimax, que
resuelve juegos por turnos de \emph{suma-cero}\footnotemark . Minimax
puede usarse para juegos en que las partes ``mueven'' al mismo tiempo,
pero ignoraremos eso y nos concentraremos en su aplicación para este
juego.
\\

\footnotetext{Brevemente, son aquellos en los cuales una ganancia de un
jugador es una pérdida directa del otro, y no existe la posibilidad de
cooperación}

El Minimax más básico funciona explorando el árbol de movidas del
juego, de a un turno, considerando todas las movidas posibles de cada
jugador, hasta llegar a un nodo terminal (juego finalizado). Dado un
nodo, calcula recursivamente el valor de cada uno de los posibles
sucesores, y devuelve el valor del ``mejor'', que es el mínimo o el
máximo, dependiendo de quien sea el turno. Cada nodo terminal tiene
un puntaje asociado según quien ganó. Para el Ajedrez, podría ser 1
cuando ganan las blancas, -1 cuando ganan las negras y 0 cuando empatan.
Minimax nos devolverá el puntaje que podemos conseguir y la movida que
debemos jugar.
\\

Hacer una búsqueda hasta los nodos terminales no funciona para juegos
con un tamaño mayor al Ta-Te-Tí (y aún ahí se nota cierta lentitud)
debido a la cantidad de nodos explorados. Recordando el factor de
ramificación promedio de 30 y las 80 media-movidas (movidas por
jugador) por partido del Ajedrez esto resulta impracticable. Por
está razón se agrega un límite de profundidad, y si llegamos a él
devolvemos un \emph{valor heurístico} del tablero, que representa
de alguna manera el puntaje de cada jugador. Con ésta modificación
Minimax nos devolverá un ``valor esperado'' y la movida que debemos
hacer.
\\

Está evaluación de tablero guiará la búsqueda casi en su
totalidad, por lo cual es necesario que realmente se corresponda con
la situación y dé puntajes adecuados según quién va ganando.
También es necesaria cierta estabilidad de esta función. Citando a
\href{http://chessprogramming.wikispaces.com/}{chessprogramming.wikispaces.com}:
\\

\noindent
\framebox{\parbox{\dimexpr\linewidth-2\fboxsep-2\fboxrule}{\itshape\center
	``It is better to be wrong by 10 centipawns all the time than to be
	completely correct 99.9\% of the time and wrong by 300 centipawns 0.1\% of
	the time.''
}}
\\

El algoritmo Minimax tiene una peculiaridad, si al analizar la primera
movida que podemos hacer generamos un jaque mate (el mejor resultado
posible), la búsqueda seguirá y calculará los valores esperados de
todos los nodos del árbol. Este caso particular podría detectarse y
mejorarse, pero hay una idea aún mejor que da resultados muchísimo
mejores: la poda Alpha-Beta.
\\

El algoritmo Alpha-Beta extiende al Minimax llevando cuenta de una
``ventana'' de búsqueda. Dos valores llamados Alpha y Beta que
representan respectivamente los puntajes ``garantizados'' del jugador
maximizante y minimizante. Por garantizado se entiende a que el jugador
puede ``forzar'' un resultado de al menos ese puntaje. Ambos se inician
en el peor resultado posible ($-\infty$ y $+\infty$ respectivamente)
y se actualizan en la búsqueda. Si en algún vemos que una movida
del jugador maximizante resulta en un puntaje mayor a Beta, podemos
asegurar que esta rama que estamos explorando no tiene sentido, debido
a que jugador minimizante seguiría otra rama (la que le da el puntaje
garantizado) en vez de la actual.
\\

El mismo corte puede ocurrir en turnos del jugador minimizante. El
algoritmo Alpha-Beta siempre da el mismo resultado que Minimax,
pero su complejidad temporal promedio disminuye de $O(b^d)$ a
$O(b^{(3d/4)})$\footnotemark. Lo que significa que podemos hacer una
búsqueda un 33\% mas de profundidad en el mismo tiempo. La complejidad
en el peor caso se mantiene ($O(b^d)$) y la del mejor caso es aún
mejor: $O(\sqrt{b^d})$ (o sea, el doble de profundidad en el mismo
tiempo). El peor y mejor caso dependen de la cantidad de cortes que
encuentre el algoritmo.
\\

\footnotetext{$b$ es el factor de ramificación promedio y $d$ la
profundidad de la búsqueda}

Estos cortes tienden a ocurrir más frecuentemente si las mejoras
movidas de cada jugador se analizan primero. Para lograr esto se emplean
muchas heurísticas de ordenamiento de movidas.
\\

En las hojas de la búsqueda Alpha-Beta, no se aplica la evaluación
de tablero directamente, si no que se realiza otro tipo de búsqueda
conocida como Búsqueda de quietud (\emph{Quiescence search}). Esta
búsqueda es un Alpha-Beta similar al anterior, pero solo considera
como movimientos válidos a los movidas que producen una captura
o promoción. El objetivo es no aplicar la evaluación de tablero
ciegamente en tableros con piezas atacadas, y forzar a que se sigan
todas las líneas de capturas. Esto hace que se disminuya el Efecto
Horizonte y el motor juegue mucho mejor (en el mismo tiempo).
\\

La búsqueda de quietud no está limitada por profundidad. En contraste,
solo termina por cortes Alpha-Beta, con la diferencia que al iniciar
la búsqueda usamos el valor actual del tablero como cota inferior de
$\alpha$ (similarmente a la Null move heuristic). Esto tiene algún
fundamento teórico, porque por lo general siempre podemos elegir una
movida que no sea una captura y terminar con la secuencia de capturas.
\\

En rasgos generales, la búsqueda es como se describió anteriormente,
pero aumentando la profundidad iterativamente hasta llegar a un límite
de tiempo (más una pequeña heurística que yo llamo Smart-Stop).
Cuando el tiempo se termina, se devuelve el resultado de la última
búsqueda que se completó íntegramente.
\\

\section{Heurísticas de ordenamiento}

Una heurística de ordenamiento es siempre teóricamente correcta.

\subsection{Killer move heuristic}
Una de las heurísticas de ordenamiento de movidas mas simple y
rendidora es la Killer move heuristic. Consiste en guardar en una tabla
la movida que generó un corte, indexada por la profundidad en la cual
se hizo la movida. Al ejecutar de nuevo la búsqueda, si la movida
guardada aparece como sucesora se le da un bonus.
\\

\subsection{Tabla de transposición}
La tabla de transposición es la manera de eliminar nodos duplicados
en la búsqueda. Al usar Alpha-Beta no podemos simplemente guardar el
resultado que devolvimos, si no que también hay que tener en cuenta
el contexto en el cual lo generamos (la ventana), y saber si estamos
tratando con un resultado exacto, o una cota superior o inferior.
\\

Supongamos que el verdadero valor del tablero es $V$. Si la búsqueda
fue llamada con $\alpha$ y $\beta$ y devuelve $v$, tenemos 3
posibilidades:

\begin{itemize}
\item Si $v \le \alpha$ entonces $v \ge V$
\item Si $v \ge \beta$ entonces $v \le V$
\item Si $\alpha < v < \beta$ entonces $v = V$
\end{itemize}

Cuando guardamos el valor en la tabla, indicamos cual fue el caso y lo
tenemos en cuenta al volver a visitar el nodo.
\\

También, guardamos en la TT la movida que causó un corte y la
puntuamos con un bonus alto.

\subsection{Countermove heuristic}
Es una heurística similar a la Killer Move, pero en vez de registrar
los cortes indexados por la profundidad de la búsqueda, lo hace según
la movida realizada anteriormente a la actual, bajo la premisa de que
hay movidas que tienen una ``respuesta natural'' independientemente de
la profundidad y el tablero. Da resultados no muy buenos, pero es fácil
de implementar.
\\

\subsection{MVV-LVA}
MVV-LVA significa ``\emph{Most valuable victim, least valuable
attacker}'', es una heurística simple que puntúa las capturas. Una
captura es mejor que otra si captura a una pieza de mayor valor, o
realiza la captura con una pieza propia de menor valor. La fórmula
usada para puntuar es $10*v - a$ en donde $v$ es el puntaje de la pieza
víctima y $a$ el puntaje de la pieza atacante.
\\

Si bien MVV-LVA es la última en esta lista, es de vital importancia
debido a que puntúa \emph{todas} las movidas, y nos da un orden
suficientemente bueno al empezar la búsqueda (cuando no hay ninguna
información guardada en las heurísticas) y también luego, al puntuar
las movidas que no encajan dentro de las otras heurísticas (que son la
mayoría).
\\

Funciona bastante bien para ser algo tan simple de implementar. En
especial para la búsqueda de quietud, en donde sólo consideramos las
capturas. Hace una diferencia muy importante en ese caso debido a que
no tenemos un límite de profundidad como en la búsqueda principal y
dependemos casi exclusivamente de los cortes.
\\

\section{Evaluación de Tablero}
Se sigue la convención de que los valores positivos favorecen al
jugador blanco y los negativos al negro. La evaluación de tablero se
hace sumando los siguientes puntajes.

\subsection{Valor de piezas}
Simplemente se suman los valores de cada pieza que tiene cada jugador. Las piezas blancas tienen valor positivo y las negras negativo. Los valores son:

\begin{center}
 \begin{tabular}{|c|c|}
  \hline
  \WhitePawnOnWhite & 100 \\
  \hline
  \WhiteKnightOnWhite & 320 \\
  \hline
  \WhiteBishopOnWhite & 320 \\
  \hline
  \WhiteRookOnWhite & 500 \\
  \hline
  \WhiteQueenOnWhite & 900 \\
  \hline
 \end{tabular}
\end{center}

Los reyes no tienen puntaje, debido a que siempre están y no influiría
en nada.

\subsection{Pieza-posición}
Una mejora simple a lo anterior es darle puntajes a las piezas según la
posición. Para esto se definen 6 tablas de 64 casillas con puntajes.
Estos puntajes suelen ser menores a los anteriores, debido a que perder
piezas es algo mucho mas severo.

Para el caso del rey, queremos que ocupe posiciones completamente
distintas en la apertura y en el juego final, por lo que usamos dos
tablas, e interpolamos según la etapa del juego.

\subsection{Estado de Jaque}
Se aplica una penalización por no haber hecho enroque, y una mas severa
si ya no es posible. Esto incentiva al motor a realizar enroque.

\subsection{Estado de filas}
Se evalua cada fila del tablero según los peones de cada jugador. Si una fila no tiene peones se la llama \emph{abierta}. Si tiene peones de un sólo jugador se la llama \emph{semi-abierta}.
\\

Una fila abierta es bastante significativa. Tener una fila abierta cerca
de nuestro rey es malo, y se aplica un penalización. Tener una torre en
una fila abierta es muy bueno y merece un bonus.

\subsection{Estado de jaque}
Si bien tratamos de no aplicar la evaluación de tablero en tableros
en jaque (preferimos extender la búsqueda) ciertas situaciones causan
que no se pueda seguir extendiendo. Si se da una de estas situaciones
restamos 100 puntos al lado en jaque, para incentivar a que se exploren
otras alternativas.

\subsection{Bonus por par de alfiles}
Simplemente si uno de los lados tiene ambos alfiles, se la da un bonus
(actualemente 15 puntos).

\subsection{King safety}
Para cada lado se evalua que tan bien está protegido el rey. Esto se
hace considerando el estado de las filas cercanas. Tener filas abiertas
es penalizado, y también preferimos tener a nuestros peones cerca y a
los del oponente lejos.
\\

El valor de King-safety se escala según las piezas del oponente. La
premisa es que nuestro rey sólo puede estar descubierto si el oponente
tiene material para poder atacarlo.
\\

Esto está fuertemente inspirado en el motor TSCP de Tom Kerrigan.

\section{Extensiones/Reducciones}

Las heurísticas de Null Move y Late Move Reductions no son
teóricamente correctas, pero dan muy buenos resultados al
implementarse. Es notable que al recortar nodos no necesariamente
perdemos fuerza del motor. De hecho, como hacemos profundización
iterativa, una buena estimación es que el motor siempre recorrerá
la misma cantidad de nodos en un tiempo dado, por lo que lo que hacen
las heurísticas es simplemente dirigir la búsqueda por los caminos
mas interesante (al hacer un corte en una rama, exploraremos más por
todas las otras). Es vital tener en cuenta eso para pensar sobre las
heurísticas siguientes.

\subsection{Extension por Jaque o promoción}
Simplemente si el tablero actual está en Jaque, o la última movida fue
una promoción de un peón, se agrega 1 a la profundidad máxima de la
rama. Esto incentiva a resolver los Jaques y promociones y no aplicar la
evaluación en un tablero muy inestable.

\subsection{Extensión por movida forzada}
Si el tablero actual tiene una sola movida posible, se agrega 1 a la
profundidad máxima, debido a que este nivel fue ``desperdiciado'' de
algunamanera.

\subsection{Reducción por Null move heuristic}
La heurística consiste en la idea intuitiva de que si podemos ceder el
turno, dándole 2 movidas a nuestro adversario, y seguimos teniendo un
tablero bueno, entonces nuestro tablero original era bueno y podemos
cortar la búsqueda.
\\

En términos computacionales esto se implementa cediendo el turno, realizando
una búsqueda menos profunda del tablero (por ejemplo, de 3 plies menos) y comparando el resultado con $\beta$. Si el resultado es mayor a $\beta$, devolvemos $\beta$ como resultado.
\\

Esto recorta mucho los nodos explorados para una cierta profundidad,
pero debido a la ilegalidad de la movida debemos tener cuidado de evitar
situaciones en donde mover nos perjudica (llamado Zugzwang)
\\

\subsection{Late Move Reductions}
La heurística LMR sigue la idea de que dado un buen ordenamiento de
movidas, es muy probable que las mejores movidas estén siempre al
principio de los sucesores, con lo cual es casi seguro que las movidas
del final de la lista fallen bajo (resulten $< \alpha$).
\\

A las movidas del final de la lista se les reduce su profundidad máxima
en 1. Si resulta que no fallan bajo (o sea, devuelven un valor mayor o
igual a $\alpha$), la búsqueda se rehace con la profundidad normal.
\\

\section{Resultados}
Durante el desarrollo se usó de oponente a Fairymax, un motor de
ajedrez basado de $\mu$-Max (Micro-Max) que juega a un nivel intermedio
(?? ELO). En la versión 0.4 de ICE, ICE parece ser claramente superior.
Se corrieron 30 partidas en formato 40/4 (40 movidas en 4 minutos) y el
resultado fue 21-2-7 (21 victorias, 2 empates, 7 derrotas) a favor de
ICE.

El registro de partidas se puede encontrar
\href{http://labdcc.fceia.unr.edu.ar/~gmartinez/ice\_fairy\_40\_4.pgn}
{aquí}:

\section{Reflexiones}
Sin duda algo a mejorar es la evaluación de tablero. Escribir una buena
función de evaluación de tablero requiere muchísimo conocimiento
del dominio, y por lo general es llevado a cabo por expertos en el
juego junto a programadores. Sin duda, yo no tengo un nivel ni siquiera
intermedio del juego, por lo cual me limité a leer y aplicar técnicas
existentes y bien conocidas.
\\

Se podría paralelizar la búsqueda, aunque esto es algo no trivial
debido a la naturaleza secuencial del Alpha-Beta. Al paralelizar
seguramente exploraríamos mas nodos que de forma secuencial, debido a
que no conoceremos exactamente la ventana en la cual tenemos que buscar.
Sin embargo, creo que se verían mejoras notables.
\\

Otras mejoras pueden ser hacer que el límite de tiempo sea algo más
inteligente (tener en cuenta cuanto tiempo lleva usado cada jugador,
y el límite del partido, si es que existe) y hacer que nuestro motor
``piense'' durante el turno del otro (conocido como \emph{Pondering}).
\\

En algunos casos, con pocas movidas posibles, es bastante claro para un
humano cual es la movida a elegir. Por ejemplo, si tenemos la opción
entre avanzar un peón y mover la reina, estando la reina amenazada, es
casi seguro que debemos mover la reina. Cómo el Alpha-Beta normal es un
algoritmo para calcular la variación principal del juego, no tiene en
cuenta que realmente sólo nos interesa saber que mover en la raíz, y
podría hacer cálculos de más.

Creo que comparando los valores de cada movida en la raíz a medida que
aumentamos la profundidad puede ayudar a tomar una decisión sobre esto.
Dicho de otra forma, solo debemos aumentar la profundidad en la medida
que nos ayude a ``desempatar'' entre movidas del nodo raíz. Esta idea
podría investigarse e implementarse.

\begin{thebibliography}{9}

\bibitem{piece-square-table}
  http://chessprogramming.wikispaces.com/Simplified+evaluation+function

\bibitem{zobrist}
  http://en.wikipedia.org/wiki/Zobrist\_hashing

\bibitem{protocol}
  http://www.gnu.org/software/xboard/engine-intf.html

\end{thebibliography}

\end{document}
